{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.spatial import ConvexHull\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "plt.style.use('ggplot')\n",
    "import pickle\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "%matplotlib inline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAuc(X,y,test_size=0.25,max_depth=None,n_estimators=100,\n",
    "           minsplit=4,FPR=[],TPR=[],VERBOSE=False, USE_ONLY=None):\n",
    "    '''\n",
    "        get AUC given training data X, with target labels y\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    CLASSIFIERS=[DecisionTreeClassifier(max_depth=max_depth, min_samples_split=minsplit,class_weight='balanced'),\n",
    "                RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                       max_depth=max_depth,min_samples_split=minsplit,class_weight='balanced'),\n",
    "                ExtraTreesClassifier(n_estimators=n_estimators,\n",
    "                                     max_depth=max_depth,min_samples_split=minsplit,class_weight='balanced'),\n",
    "                AdaBoostClassifier(n_estimators=n_estimators),\n",
    "                GradientBoostingClassifier(n_estimators=n_estimators,max_depth=max_depth),\n",
    "                svm.SVC(kernel='rbf',gamma='scale',class_weight='balanced',probability=True)]\n",
    "\n",
    "    if USE_ONLY is not None:\n",
    "        if isinstance(USE_ONLY, (list,)):\n",
    "            CLASSIFIERS=[CLASSIFIERS[i] for i in USE_ONLY]\n",
    "        if isinstance(USE_ONLY, (int,)):\n",
    "            CLASSIFIERS=CLASSIFIERS[USE_ONLY]\n",
    "\n",
    "    for clf in CLASSIFIERS:\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred=clf.predict_proba(X_test)\n",
    "        #print(X_test,y_pred)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test,y_pred[:,1], pos_label=1)\n",
    "        auc=metrics.auc(fpr, tpr)\n",
    "        if VERBOSE:\n",
    "            print(auc)\n",
    "\n",
    "        FPR=np.append(FPR,fpr)\n",
    "        TPR=np.append(TPR,tpr)\n",
    "    points=np.array([[a[0],a[1]] for a in zip(FPR,TPR)])\n",
    "    hull = ConvexHull(points)\n",
    "    x=np.argsort(points[hull.vertices,:][:,0])\n",
    "    auc=metrics.auc(points[hull.vertices,:][x,0],points[hull.vertices,:][x,1])\n",
    "    return auc,CLASSIFIERS\n",
    "\n",
    "\n",
    "def saveFIG(filename='tmp.pdf',AXIS=False):\n",
    "    '''\n",
    "        save fig for publication\n",
    "    '''\n",
    "    import pylab as plt\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "            hspace = 0, wspace = 0)\n",
    "    plt.margins(0,0)\n",
    "    if not AXIS:\n",
    "        plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "        plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.savefig(filename,dpi=300, bbox_inches = 'tight',\n",
    "                pad_inches = 0,transparent=False) \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCoverage(model,verbose=True):\n",
    "    '''\n",
    "        return how many distinct items (questions)\n",
    "        are used in the model set.\n",
    "        This includes the set of questions being\n",
    "        covered by all forms that may be \n",
    "        generated by the model set\n",
    "    '''\n",
    "    FS=[]\n",
    "    for m in model:\n",
    "        for count in range(len(m.estimators_)):\n",
    "            clf=m.estimators_[count]\n",
    "            fs=clf.tree_.feature[clf.tree_.feature>0]\n",
    "            FS=np.array(list(set(np.append(FS,fs))))\n",
    "    if verbose:\n",
    "        print(\"Number of items used: \", FS.size)\n",
    "    return FS\n",
    "\n",
    "def getConfusion(X,y,test_size=0.25,max_depth=None,n_estimators=100,\n",
    "           minsplit=4,CONFUSION={},VERBOSE=False, USE_ONLY=None,target_names = None):\n",
    "    '''\n",
    "        get AUC given training data X, with target labels y\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    CLASSIFIERS=[DecisionTreeClassifier(max_depth=max_depth, min_samples_split=minsplit),\n",
    "                RandomForestClassifier(n_estimators=n_estimators,class_weight='balanced',\n",
    "                                       max_depth=max_depth,min_samples_split=minsplit),\n",
    "                ExtraTreesClassifier(n_estimators=n_estimators,class_weight='balanced',\n",
    "                                     max_depth=max_depth,min_samples_split=minsplit),\n",
    "                AdaBoostClassifier(n_estimators=n_estimators),\n",
    "                GradientBoostingClassifier(n_estimators=n_estimators,max_depth=max_depth),\n",
    "                svm.SVC(kernel='rbf',gamma='scale',class_weight='balanced',probability=True)]\n",
    "\n",
    "    if USE_ONLY is not None:\n",
    "        if isinstance(USE_ONLY, (list,)):\n",
    "            CLASSIFIERS=[CLASSIFIERS[i] for i in USE_ONLY]\n",
    "        if isinstance(USE_ONLY, (int,)):\n",
    "            CLASSIFIERS=CLASSIFIERS[USE_ONLY]\n",
    "\n",
    "    for clf in CLASSIFIERS:\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred=clf.predict(X_test)\n",
    "        print(y_test,y_pred)\n",
    "        cmat=confusion_matrix(y_test, y_pred)\n",
    "        acc=accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        CONFUSION[clf]=cmat\n",
    "        \n",
    "        if VERBOSE:\n",
    "            print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "            print('Confusion MAtrix:\\n', cmat)\n",
    "            print(' ')\n",
    "            print('Accuracy:', acc)\n",
    "\n",
    "        \n",
    "    return CONFUSION,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "      <th>Biotype</th>\n",
       "      <th>panss_p1</th>\n",
       "      <th>panss_p2</th>\n",
       "      <th>panss_p3</th>\n",
       "      <th>panss_p4</th>\n",
       "      <th>panss_p5</th>\n",
       "      <th>panss_p6</th>\n",
       "      <th>panss_p7</th>\n",
       "      <th>panss_n1</th>\n",
       "      <th>...</th>\n",
       "      <th>young_9</th>\n",
       "      <th>young_10</th>\n",
       "      <th>young_11</th>\n",
       "      <th>sfs_setotal</th>\n",
       "      <th>sfs_ictotal</th>\n",
       "      <th>sfs_ipcptotal</th>\n",
       "      <th>sfs_ipcctotal</th>\n",
       "      <th>sfs_retotal</th>\n",
       "      <th>sfs_prototal</th>\n",
       "      <th>sfs_oetotal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            project  Biotype  panss_p1  panss_p2  panss_p3  panss_p4  \\\n",
       "subject_id                                                             \n",
       "1               1.0        2       4.0       3.0       4.0       1.0   \n",
       "4               1.0        5       3.0       1.0       3.0       1.0   \n",
       "53              1.0        2       4.0       3.0       5.0       2.0   \n",
       "73              1.0        2       6.0       5.0       6.0       4.0   \n",
       "78              1.0        1       2.0       2.0       1.0       1.0   \n",
       "\n",
       "            panss_p5  panss_p6  panss_p7  panss_n1  ...  young_9  young_10  \\\n",
       "subject_id                                          ...                      \n",
       "1                3.0       2.0       1.0       4.0  ...      0.0       1.0   \n",
       "4                2.0       2.0       1.0       3.0  ...      0.0       0.0   \n",
       "53               1.0       3.0       1.0       5.0  ...      0.0       1.5   \n",
       "73               5.0       6.0       6.0       1.0  ...      2.0       1.0   \n",
       "78               1.0       1.0       1.0       3.0  ...      0.0       0.0   \n",
       "\n",
       "            young_11  sfs_setotal  sfs_ictotal  sfs_ipcptotal  sfs_ipcctotal  \\\n",
       "subject_id                                                                     \n",
       "1                2.0          9.0          8.0           27.0            NaN   \n",
       "4                0.0          7.0          8.0           19.0            NaN   \n",
       "53               0.0         10.0          4.0           24.0           31.0   \n",
       "73               4.0          7.0          7.0           21.0           18.0   \n",
       "78               0.0          9.0          9.0           36.0           39.0   \n",
       "\n",
       "            sfs_retotal  sfs_prototal  sfs_oetotal  \n",
       "subject_id                                          \n",
       "1                  25.0          45.0          5.0  \n",
       "4                  13.0           9.0          4.0  \n",
       "53                 10.0          17.0          0.0  \n",
       "73                 15.0          11.0         10.0  \n",
       "78                 13.0          12.0          1.0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('bsnip.csv',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    595\n",
       "5    500\n",
       "2    446\n",
       "Name: Biotype, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 is HC\n",
    "df.Biotype.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df[df['Biotype']==3]\n",
    "df=df.dropna()\n",
    "df0=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1541, 58)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df=df0[df0.Biotype.isin([1,5])]\n",
    "df=df0\n",
    "X=df.iloc[:,2:].values\n",
    "y=df.Biotype.values#.astype(str)\n",
    "y5=[(int(x)==5)+0 for x in y ]\n",
    "y1=[(int(x)==1)+0 for x in y ]\n",
    "y2=[(int(x)==2)+0 for x in y ]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X, y, test_size=0.2)\n",
    "y5=[(int(x)==5)+0 for x in y_train_ ]\n",
    "y1=[(int(x)==1)+0 for x in y_train_ ]\n",
    "y2=[(int(x)==2)+0 for x in y_train_ ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 132.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7426079109542696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ACC=[]\n",
    "CLFh={}\n",
    "for run in tqdm(np.arange(500)):\n",
    "    auc,CLFS=getAuc(X_train_,y5,test_size=0.2,max_depth=10,n_estimators=2,\n",
    "               minsplit=2,VERBOSE=False, USE_ONLY=[2])\n",
    "    ACC=np.append(ACC,auc)\n",
    "    if auc > 0.75:\n",
    "        CLFh[auc]=CLFS\n",
    "#sns.distplot(ACC)\n",
    "print(np.median(ACC))\n",
    "CLFstar5=CLFh[np.array([k for k in CLFh.keys()]).max()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 131.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6965697599794635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ACC=[]\n",
    "CLFh={}\n",
    "for run in tqdm(np.arange(500)):\n",
    "    auc,CLFS=getAuc(X_train_,y1,test_size=0.2,max_depth=10,n_estimators=2,\n",
    "               minsplit=2,VERBOSE=False, USE_ONLY=[2])\n",
    "    ACC=np.append(ACC,auc)\n",
    "    if auc > 0.65:\n",
    "        CLFh[auc]=CLFS\n",
    "#sns.distplot(ACC)\n",
    "print(np.median(ACC))\n",
    "CLFstar1=CLFh[np.array([k for k in CLFh.keys()]).max()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 134.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6701701040014101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ACC=[]\n",
    "CLFh={}\n",
    "for run in tqdm(np.arange(500)):\n",
    "    auc,CLFS=getAuc(X_train_,y2,test_size=0.2,max_depth=10,n_estimators=2,\n",
    "               minsplit=2,VERBOSE=False, USE_ONLY=[2])\n",
    "    ACC=np.append(ACC,auc)\n",
    "    if auc > 0.75:\n",
    "        CLFh[auc]=CLFS\n",
    "#sns.distplot(ACC)\n",
    "print(np.median(ACC))\n",
    "CLFstar2=CLFh[np.array([k for k in CLFh.keys()]).max()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309\n",
      "0.5307443365695793 [[0.65346535 0.1980198  0.14851485]\n",
      " [0.28181818 0.39090909 0.32727273]\n",
      " [0.32653061 0.1122449  0.56122449]]\n"
     ]
    }
   ],
   "source": [
    "y_pred5p=CLFstar5.predict_proba(X_test_)\n",
    "y_pred1p=CLFstar1.predict_proba(X_test_)\n",
    "y_pred2p=CLFstar2.predict_proba(X_test_)\n",
    "\n",
    "Y=[]\n",
    "a=1\n",
    "for (i,j,k) in zip(y_pred1p[:,1]**a,y_pred5p[:,1]**a,y_pred2p[:,1]**a):\n",
    "    idx=np.argmax([i,j,k])\n",
    "    #print(idx)\n",
    "    if idx == 0:\n",
    "        l=1\n",
    "        Y=np.append(Y,l)   \n",
    "        continue\n",
    "    if idx == 1:\n",
    "        l=5\n",
    "        Y=np.append(Y,l)   \n",
    "        continue\n",
    "    if idx == 2:\n",
    "        l=2\n",
    "        Y=np.append(Y,l)   \n",
    "        continue\n",
    "print(len(Y))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ACC=accuracy_score(y_test_, Y)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C=confusion_matrix(y_test_, Y)\n",
    "row_sums = C.sum(axis=1)\n",
    "C1 = C / row_sums[:, np.newaxis]\n",
    "print(ACC,C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771\n",
      "0.06874189364461739 [[0.05226481 0.34494774 0.60278746]\n",
      " [0.456621   0.08219178 0.46118721]\n",
      " [0.53584906 0.38867925 0.0754717 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in power\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "y_pred5p=CLFstar5.predict_proba(X_test)\n",
    "y_pred1p=CLFstar1.predict_proba(X_test)\n",
    "y_pred2p=CLFstar2.predict_proba(X_test)\n",
    "\n",
    "Y=[]\n",
    "a=-.3\n",
    "for (i,j,k) in zip(y_pred1p[:,1]**a,y_pred5p[:,1]**a,y_pred2p[:,1]**a):\n",
    "    idx=np.argmax([i,j,k])\n",
    "    #print(idx)\n",
    "    if idx == 0:\n",
    "        l=1\n",
    "        Y=np.append(Y,l)   \n",
    "        continue\n",
    "    if idx == 1:\n",
    "        l=5\n",
    "        Y=np.append(Y,l)   \n",
    "        continue\n",
    "    if idx == 2:\n",
    "        l=2\n",
    "        Y=np.append(Y,l)   \n",
    "        continue\n",
    "print(len(Y))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ACC=accuracy_score(y_test, Y)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C=confusion_matrix(y_test, Y)\n",
    "row_sums = C.sum(axis=1)\n",
    "C1 = C / row_sums[:, np.newaxis]\n",
    "print(ACC,C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8058252427184466 [[0.87155963 0.05504587 0.0733945 ]\n",
      " [0.14736842 0.64210526 0.21052632]\n",
      " [0.0952381  0.01904762 0.88571429]]\n",
      "0.8187702265372169 [[0.83185841 0.09734513 0.07079646]\n",
      " [0.06593407 0.76923077 0.16483516]\n",
      " [0.1047619  0.04761905 0.84761905]]\n",
      "0.8155339805825242 [[0.8559322  0.06779661 0.07627119]\n",
      " [0.13483146 0.74157303 0.12359551]\n",
      " [0.1372549  0.02941176 0.83333333]]\n",
      "0.8414239482200647 [[0.90983607 0.04918033 0.04098361]\n",
      " [0.1011236  0.76404494 0.13483146]\n",
      " [0.12244898 0.05102041 0.82653061]]\n",
      "0.8414239482200647 [[0.87704918 0.06557377 0.05737705]\n",
      " [0.10227273 0.79545455 0.10227273]\n",
      " [0.14141414 0.02020202 0.83838384]]\n",
      "0.8122977346278317 [[0.83606557 0.08196721 0.08196721]\n",
      " [0.11627907 0.69767442 0.18604651]\n",
      " [0.08910891 0.02970297 0.88118812]]\n",
      "0.8090614886731392 [[0.86885246 0.05737705 0.07377049]\n",
      " [0.11956522 0.68478261 0.19565217]\n",
      " [0.08421053 0.06315789 0.85263158]]\n",
      "0.8220064724919094 [[0.864      0.064      0.072     ]\n",
      " [0.12903226 0.74193548 0.12903226]\n",
      " [0.08791209 0.06593407 0.84615385]]\n",
      "0.7896440129449838 [[0.78947368 0.10526316 0.10526316]\n",
      " [0.08695652 0.73913043 0.17391304]\n",
      " [0.08737864 0.0776699  0.83495146]]\n",
      "0.8576051779935275 [[0.86554622 0.08403361 0.05042017]\n",
      " [0.09638554 0.8313253  0.07228916]\n",
      " [0.11214953 0.01869159 0.86915888]]\n",
      "0.8155339805825242 [[0.85245902 0.05737705 0.09016393]\n",
      " [0.125      0.7875     0.0875    ]\n",
      " [0.1682243  0.03738318 0.79439252]]\n",
      "0.8317152103559871 [[0.84       0.08       0.08      ]\n",
      " [0.12048193 0.74698795 0.13253012]\n",
      " [0.04950495 0.05940594 0.89108911]]\n",
      "0.8317152103559871 [[0.84955752 0.07079646 0.07964602]\n",
      " [0.07865169 0.78651685 0.13483146]\n",
      " [0.07476636 0.07476636 0.85046729]]\n",
      "0.8349514563106796 [[0.88709677 0.07258065 0.04032258]\n",
      " [0.15053763 0.68817204 0.16129032]\n",
      " [0.0326087  0.05434783 0.91304348]]\n",
      "0.8058252427184466 [[0.88695652 0.04347826 0.06956522]\n",
      " [0.11       0.74       0.15      ]\n",
      " [0.14893617 0.07446809 0.77659574]]\n",
      "0.8122977346278317 [[0.90566038 0.05660377 0.03773585]\n",
      " [0.18269231 0.71153846 0.10576923]\n",
      " [0.14141414 0.04040404 0.81818182]]\n",
      "0.8187702265372169 [[0.83846154 0.1        0.06153846]\n",
      " [0.07142857 0.77380952 0.1547619 ]\n",
      " [0.09473684 0.07368421 0.83157895]]\n",
      "0.7961165048543689 [[0.85123967 0.11570248 0.03305785]\n",
      " [0.11494253 0.71264368 0.17241379]\n",
      " [0.15841584 0.03960396 0.8019802 ]]\n",
      "0.8284789644012945 [[0.82051282 0.09401709 0.08547009]\n",
      " [0.10638298 0.74468085 0.14893617]\n",
      " [0.04081633 0.04081633 0.91836735]]\n",
      "0.7799352750809061 [[0.79365079 0.12698413 0.07936508]\n",
      " [0.15294118 0.68235294 0.16470588]\n",
      " [0.12244898 0.03061224 0.84693878]]\n",
      "0.7928802588996764 [[0.8        0.10434783 0.09565217]\n",
      " [0.13333333 0.71111111 0.15555556]\n",
      " [0.10576923 0.03846154 0.85576923]]\n",
      "0.8381877022653722 [[0.88617886 0.08130081 0.03252033]\n",
      " [0.13541667 0.77083333 0.09375   ]\n",
      " [0.13333333 0.02222222 0.84444444]]\n",
      "0.8381877022653722 [[0.93693694 0.04504505 0.01801802]\n",
      " [0.1010101  0.68686869 0.21212121]\n",
      " [0.07070707 0.05050505 0.87878788]]\n",
      "0.8414239482200647 [[0.83760684 0.07692308 0.08547009]\n",
      " [0.09210526 0.77631579 0.13157895]\n",
      " [0.07758621 0.03448276 0.88793103]]\n",
      "0.8058252427184466 [[0.8487395  0.08403361 0.06722689]\n",
      " [0.09782609 0.75       0.15217391]\n",
      " [0.12244898 0.07142857 0.80612245]]\n",
      "0.8317152103559871 [[0.86440678 0.05084746 0.08474576]\n",
      " [0.1122449  0.75510204 0.13265306]\n",
      " [0.06451613 0.06451613 0.87096774]]\n",
      "0.7961165048543689 [[0.82857143 0.1047619  0.06666667]\n",
      " [0.0952381  0.73333333 0.17142857]\n",
      " [0.12121212 0.05050505 0.82828283]]\n",
      "0.8381877022653722 [[0.87603306 0.05785124 0.0661157 ]\n",
      " [0.1011236  0.79775281 0.1011236 ]\n",
      " [0.14141414 0.03030303 0.82828283]]\n",
      "0.8220064724919094 [[0.85470085 0.05982906 0.08547009]\n",
      " [0.11702128 0.72340426 0.15957447]\n",
      " [0.08163265 0.04081633 0.87755102]]\n",
      "0.8349514563106796 [[0.89166667 0.075      0.03333333]\n",
      " [0.09411765 0.72941176 0.17647059]\n",
      " [0.10576923 0.03846154 0.85576923]]\n",
      "0.8187702265372169 [[0.86206897 0.0862069  0.05172414]\n",
      " [0.11340206 0.72164948 0.16494845]\n",
      " [0.10416667 0.03125    0.86458333]]\n",
      "0.8058252427184466 [[0.84482759 0.06896552 0.0862069 ]\n",
      " [0.18666667 0.69333333 0.12      ]\n",
      " [0.11016949 0.05084746 0.83898305]]\n",
      "0.8317152103559871 [[0.85074627 0.10447761 0.04477612]\n",
      " [0.10588235 0.74117647 0.15294118]\n",
      " [0.1        0.01111111 0.88888889]]\n",
      "0.8058252427184466 [[0.84722222 0.0625     0.09027778]\n",
      " [0.11392405 0.74683544 0.13924051]\n",
      " [0.12790698 0.08139535 0.79069767]]\n",
      "0.7766990291262136 [[0.82307692 0.09230769 0.08461538]\n",
      " [0.09090909 0.7012987  0.20779221]\n",
      " [0.15686275 0.06862745 0.7745098 ]]\n",
      "0.8090614886731392 [[0.81415929 0.08849558 0.09734513]\n",
      " [0.08695652 0.79347826 0.11956522]\n",
      " [0.14423077 0.03846154 0.81730769]]\n",
      "0.8058252427184466 [[0.86259542 0.08396947 0.05343511]\n",
      " [0.1097561  0.7195122  0.17073171]\n",
      " [0.10416667 0.09375    0.80208333]]\n",
      "0.8090614886731392 [[0.85365854 0.06504065 0.08130081]\n",
      " [0.12162162 0.74324324 0.13513514]\n",
      " [0.10714286 0.08928571 0.80357143]]\n",
      "0.8187702265372169 [[0.84482759 0.06034483 0.09482759]\n",
      " [0.12941176 0.69411765 0.17647059]\n",
      " [0.05555556 0.05555556 0.88888889]]\n",
      "0.8155339805825242 [[0.85123967 0.09090909 0.05785124]\n",
      " [0.13636364 0.72727273 0.13636364]\n",
      " [0.1        0.05       0.85      ]]\n",
      "0.7702265372168284 [[0.8030303  0.12878788 0.06818182]\n",
      " [0.1686747  0.68674699 0.14457831]\n",
      " [0.14893617 0.05319149 0.79787234]]\n",
      "0.8090614886731392 [[0.87755102 0.10204082 0.02040816]\n",
      " [0.16037736 0.68867925 0.1509434 ]\n",
      " [0.0952381  0.03809524 0.86666667]]\n",
      "0.8414239482200647 [[0.84615385 0.06153846 0.09230769]\n",
      " [0.06593407 0.81318681 0.12087912]\n",
      " [0.09090909 0.04545455 0.86363636]]\n",
      "0.7961165048543689 [[0.87179487 0.05128205 0.07692308]\n",
      " [0.16666667 0.69607843 0.1372549 ]\n",
      " [0.11111111 0.07777778 0.81111111]]\n",
      "0.8349514563106796 [[0.8559322  0.05932203 0.08474576]\n",
      " [0.09433962 0.76415094 0.14150943]\n",
      " [0.08235294 0.02352941 0.89411765]]\n",
      "0.8220064724919094 [[0.86666667 0.06666667 0.06666667]\n",
      " [0.08433735 0.77108434 0.14457831]\n",
      " [0.12264151 0.06603774 0.81132075]]\n",
      "0.7896440129449838 [[0.83739837 0.07317073 0.08943089]\n",
      " [0.14117647 0.67058824 0.18823529]\n",
      " [0.11881188 0.04950495 0.83168317]]\n",
      "0.8414239482200647 [[0.8880597  0.04477612 0.06716418]\n",
      " [0.10843373 0.77108434 0.12048193]\n",
      " [0.10869565 0.05434783 0.83695652]]\n",
      "0.8122977346278317 [[0.84920635 0.07936508 0.07142857]\n",
      " [0.13483146 0.75280899 0.11235955]\n",
      " [0.10638298 0.07446809 0.81914894]]\n",
      "0.7928802588996764 [[0.84347826 0.09565217 0.06086957]\n",
      " [0.14583333 0.69791667 0.15625   ]\n",
      " [0.12244898 0.05102041 0.82653061]]\n",
      "0.7831715210355987 [[0.81896552 0.10344828 0.07758621]\n",
      " [0.13333333 0.7        0.16666667]\n",
      " [0.12621359 0.05825243 0.81553398]]\n",
      "0.8220064724919094 [[0.83739837 0.04065041 0.12195122]\n",
      " [0.11827957 0.75268817 0.12903226]\n",
      " [0.08602151 0.04301075 0.87096774]]\n",
      "0.7864077669902912 [[0.78333333 0.10833333 0.10833333]\n",
      " [0.15909091 0.68181818 0.15909091]\n",
      " [0.04950495 0.06930693 0.88118812]]\n",
      "0.8025889967637541 [[0.83050847 0.05084746 0.11864407]\n",
      " [0.15       0.725      0.125     ]\n",
      " [0.08108108 0.09009009 0.82882883]]\n",
      "0.7993527508090615 [[0.83333333 0.09649123 0.07017544]\n",
      " [0.14141414 0.73737374 0.12121212]\n",
      " [0.125      0.05208333 0.82291667]]\n",
      "0.8090614886731392 [[0.85245902 0.09836066 0.04918033]\n",
      " [0.12903226 0.67741935 0.19354839]\n",
      " [0.10638298 0.0106383  0.88297872]]\n",
      "0.8058252427184466 [[0.90654206 0.02803738 0.06542056]\n",
      " [0.19       0.71       0.1       ]\n",
      " [0.16666667 0.03921569 0.79411765]]\n",
      "0.7864077669902912 [[0.79230769 0.07692308 0.13076923]\n",
      " [0.1369863  0.69863014 0.16438356]\n",
      " [0.12264151 0.03773585 0.83962264]]\n",
      "0.8187702265372169 [[0.89922481 0.04651163 0.05426357]\n",
      " [0.16666667 0.67948718 0.15384615]\n",
      " [0.14705882 0.02941176 0.82352941]]\n",
      "0.8317152103559871 [[0.85245902 0.10655738 0.04098361]\n",
      " [0.09756098 0.79268293 0.1097561 ]\n",
      " [0.13333333 0.02857143 0.83809524]]\n",
      "0.8220064724919094 [[0.89830508 0.05084746 0.05084746]\n",
      " [0.16326531 0.70408163 0.13265306]\n",
      " [0.09677419 0.05376344 0.84946237]]\n",
      "0.8058252427184466 [[0.88034188 0.06837607 0.05128205]\n",
      " [0.09183673 0.69387755 0.21428571]\n",
      " [0.14893617 0.0212766  0.82978723]]\n",
      "0.8511326860841424 [[0.89230769 0.06923077 0.03846154]\n",
      " [0.1097561  0.7804878  0.1097561 ]\n",
      " [0.11340206 0.03092784 0.8556701 ]]\n",
      "0.8090614886731392 [[0.81651376 0.08256881 0.10091743]\n",
      " [0.08910891 0.75247525 0.15841584]\n",
      " [0.12121212 0.02020202 0.85858586]]\n",
      "0.8446601941747572 [[0.8828125  0.078125   0.0390625 ]\n",
      " [0.09411765 0.72941176 0.17647059]\n",
      " [0.07291667 0.03125    0.89583333]]\n",
      "0.8317152103559871 [[0.89344262 0.04098361 0.06557377]\n",
      " [0.1375     0.7375     0.125     ]\n",
      " [0.10280374 0.06542056 0.8317757 ]]\n",
      "0.7766990291262136 [[0.84070796 0.09734513 0.0619469 ]\n",
      " [0.14606742 0.69662921 0.15730337]\n",
      " [0.14018692 0.08411215 0.77570093]]\n",
      "0.8349514563106796 [[0.83064516 0.05645161 0.11290323]\n",
      " [0.09195402 0.7816092  0.12643678]\n",
      " [0.07142857 0.04081633 0.8877551 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8220064724919094 [[0.88392857 0.03571429 0.08035714]\n",
      " [0.13483146 0.69662921 0.16853933]\n",
      " [0.09259259 0.0462963  0.86111111]]\n",
      "0.7799352750809061 [[0.84615385 0.06837607 0.08547009]\n",
      " [0.09782609 0.7173913  0.18478261]\n",
      " [0.19       0.05       0.76      ]]\n",
      "0.8252427184466019 [[0.859375   0.0859375  0.0546875 ]\n",
      " [0.08536585 0.74390244 0.17073171]\n",
      " [0.09090909 0.06060606 0.84848485]]\n",
      "0.8090614886731392 [[0.86607143 0.05357143 0.08035714]\n",
      " [0.12903226 0.74193548 0.12903226]\n",
      " [0.125      0.06730769 0.80769231]]\n",
      "0.7961165048543689 [[0.82352941 0.06722689 0.1092437 ]\n",
      " [0.14634146 0.67073171 0.18292683]\n",
      " [0.07407407 0.06481481 0.86111111]]\n",
      "0.8122977346278317 [[0.84552846 0.08130081 0.07317073]\n",
      " [0.12765957 0.71276596 0.15957447]\n",
      " [0.10869565 0.02173913 0.86956522]]\n",
      "0.8349514563106796 [[0.88095238 0.04761905 0.07142857]\n",
      " [0.15584416 0.76623377 0.07792208]\n",
      " [0.11320755 0.05660377 0.83018868]]\n",
      "0.8122977346278317 [[0.86290323 0.07258065 0.06451613]\n",
      " [0.13580247 0.67901235 0.18518519]\n",
      " [0.08653846 0.05769231 0.85576923]]\n",
      "0.8090614886731392 [[0.87681159 0.03623188 0.08695652]\n",
      " [0.11538462 0.71794872 0.16666667]\n",
      " [0.16129032 0.05376344 0.78494624]]\n",
      "0.8058252427184466 [[0.9        0.075      0.025     ]\n",
      " [0.19791667 0.64583333 0.15625   ]\n",
      " [0.12903226 0.02150538 0.84946237]]\n",
      "0.8446601941747572 [[0.91803279 0.04918033 0.03278689]\n",
      " [0.09090909 0.76136364 0.14772727]\n",
      " [0.13131313 0.04040404 0.82828283]]\n",
      "0.8284789644012945 [[0.79646018 0.10619469 0.09734513]\n",
      " [0.05617978 0.79775281 0.14606742]\n",
      " [0.09345794 0.01869159 0.88785047]]\n",
      "0.7702265372168284 [[0.78151261 0.13445378 0.08403361]\n",
      " [0.11702128 0.71276596 0.17021277]\n",
      " [0.13541667 0.05208333 0.8125    ]]\n",
      "0.8317152103559871 [[0.859375   0.0859375  0.0546875 ]\n",
      " [0.10843373 0.75903614 0.13253012]\n",
      " [0.10204082 0.04081633 0.85714286]]\n",
      "0.8252427184466019 [[0.85470085 0.06837607 0.07692308]\n",
      " [0.0989011  0.75824176 0.14285714]\n",
      " [0.08910891 0.05940594 0.85148515]]\n",
      "0.8284789644012945 [[0.86607143 0.08035714 0.05357143]\n",
      " [0.11235955 0.73033708 0.15730337]\n",
      " [0.09259259 0.03703704 0.87037037]]\n",
      "0.7864077669902912 [[0.86138614 0.05940594 0.07920792]\n",
      " [0.08910891 0.7029703  0.20792079]\n",
      " [0.1682243  0.03738318 0.79439252]]\n",
      "0.8187702265372169 [[0.85123967 0.10743802 0.04132231]\n",
      " [0.10989011 0.76923077 0.12087912]\n",
      " [0.12371134 0.05154639 0.82474227]]\n",
      "0.8317152103559871 [[0.90756303 0.06722689 0.02521008]\n",
      " [0.08235294 0.71764706 0.2       ]\n",
      " [0.0952381  0.06666667 0.83809524]]\n",
      "0.8349514563106796 [[0.84684685 0.07207207 0.08108108]\n",
      " [0.08247423 0.81443299 0.10309278]\n",
      " [0.12871287 0.02970297 0.84158416]]\n",
      "0.8220064724919094 [[0.85714286 0.07563025 0.06722689]\n",
      " [0.06185567 0.72164948 0.21649485]\n",
      " [0.06451613 0.05376344 0.88172043]]\n",
      "0.8317152103559871 [[0.88429752 0.0661157  0.04958678]\n",
      " [0.1        0.72222222 0.17777778]\n",
      " [0.08163265 0.05102041 0.86734694]]\n",
      "0.8349514563106796 [[0.8828125  0.078125   0.0390625 ]\n",
      " [0.06097561 0.73170732 0.20731707]\n",
      " [0.09090909 0.05050505 0.85858586]]\n",
      "0.8317152103559871 [[0.86046512 0.03100775 0.10852713]\n",
      " [0.10810811 0.74324324 0.14864865]\n",
      " [0.09433962 0.04716981 0.85849057]]\n",
      "0.8220064724919094 [[0.84482759 0.06034483 0.09482759]\n",
      " [0.09876543 0.79012346 0.11111111]\n",
      " [0.14285714 0.03571429 0.82142857]]\n",
      "0.8155339805825242 [[0.88392857 0.08035714 0.03571429]\n",
      " [0.12765957 0.69148936 0.18085106]\n",
      " [0.09708738 0.04854369 0.85436893]]\n",
      "0.8090614886731392 [[0.87692308 0.06153846 0.06153846]\n",
      " [0.13414634 0.7195122  0.14634146]\n",
      " [0.12371134 0.08247423 0.79381443]]\n",
      "0.8187702265372169 [[0.82258065 0.09677419 0.08064516]\n",
      " [0.1011236  0.76404494 0.13483146]\n",
      " [0.11458333 0.02083333 0.86458333]]\n",
      "0.7993527508090615 [[0.86885246 0.07377049 0.05737705]\n",
      " [0.18367347 0.69387755 0.12244898]\n",
      " [0.14606742 0.03370787 0.82022472]]\n",
      "0.8058252427184466 [[0.84615385 0.08461538 0.06923077]\n",
      " [0.17977528 0.70786517 0.11235955]\n",
      " [0.08888889 0.06666667 0.84444444]]\n",
      "0.8187702265372169 [[0.90654206 0.06542056 0.02803738]\n",
      " [0.13265306 0.67346939 0.19387755]\n",
      " [0.08653846 0.04807692 0.86538462]]\n",
      "0.8252427184466019 [[0.8974359  0.05982906 0.04273504]\n",
      " [0.14851485 0.69306931 0.15841584]\n",
      " [0.07692308 0.04395604 0.87912088]]\n"
     ]
    }
   ],
   "source": [
    "for runs in np.arange(100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    y_pred5p=CLFstar5.predict_proba(X_test)\n",
    "    y_pred1p=CLFstar1.predict_proba(X_test)\n",
    "    y_pred2p=CLFstar2.predict_proba(X_test)\n",
    "\n",
    "    Y=[]\n",
    "    a=1\n",
    "    for (i,j,k) in zip(y_pred1p[:,1]**a,y_pred5p[:,1]**a,y_pred2p[:,1]**a):\n",
    "        idx=np.argmax([i,j,k])\n",
    "        #print(idx)\n",
    "        if idx == 0:\n",
    "            l=1\n",
    "            Y=np.append(Y,l)   \n",
    "            continue\n",
    "        if idx == 1:\n",
    "            l=5\n",
    "            Y=np.append(Y,l)   \n",
    "            continue\n",
    "        if idx == 2:\n",
    "            l=2\n",
    "            Y=np.append(Y,l)   \n",
    "            continue\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    ACC=accuracy_score(y_test, Y)\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    C=confusion_matrix(y_test, Y)\n",
    "    row_sums = C.sum(axis=1)\n",
    "    C1 = C / row_sums[:, np.newaxis]\n",
    "    print(ACC,C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 170.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3ad8af0e48>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RUNS=500\n",
    "A=[]\n",
    "for run in tqdm(np.arange(RUNS)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    y_pred5=CLFstar5.predict(X_test)\n",
    "    y_pred1=CLFstar1.predict(X_test)\n",
    "    Y=[]\n",
    "    for (i,j) in zip(y_pred1,y_pred5):\n",
    "        if i==0 and j==1:\n",
    "            k=5\n",
    "        if i==1 and j==0:\n",
    "            k=1\n",
    "        if i==0 and j==0:\n",
    "            k=2\n",
    "        if i==1 and j==1:\n",
    "            k=1\n",
    "        Y=np.append(Y,k)   \n",
    "    A=np.append(A,accuracy_score(y_test, Y))\n",
    "sns.distplot(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "y_pred5=CLFstar5.predict(X)\n",
    "y_pred1=CLFstar1.predict(X)\n",
    "Y=[]\n",
    "for (i,j) in zip(y_pred1,y_pred5):\n",
    "    if i==0 and j==1:\n",
    "        k=5\n",
    "    if i==1 and j==0:\n",
    "        k=1\n",
    "    if i==0 and j==0:\n",
    "        k=2\n",
    "    if i==1 and j==1:\n",
    "        k=1\n",
    "    Y=np.append(Y,k)   \n",
    "ACC=accuracy_score(y_test, Y)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C=confusion_matrix(y_test, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[116,   7,   5],\n",
       "       [ 12,  56,  12],\n",
       "       [ 16,   8,  77]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCoverage(model,verbose=True):\n",
    "    '''\n",
    "        return how many distinct items (questions)\n",
    "        are used in the model set.\n",
    "        This includes the set of questions being\n",
    "        covered by all forms that may be \n",
    "        generated by the model set\n",
    "    '''\n",
    "    FS=[]\n",
    "    for m in model:\n",
    "        for count in range(len(m.estimators_)):\n",
    "            clf=m.estimators_[count]\n",
    "            fs=clf.tree_.feature[clf.tree_.feature>0]\n",
    "            FS=np.array(list(set(np.append(FS,fs))))\n",
    "    if verbose:\n",
    "        print(\"Number of items used: \", FS.size)\n",
    "    return FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ExtraTreeClassifier' object has no attribute 'estimators_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-5b4df69988f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetCoverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCLFstar1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-68-90d2edf3cd23>\u001b[0m in \u001b[0;36mgetCoverage\u001b[0;34m(model, verbose)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mFS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ExtraTreeClassifier' object has no attribute 'estimators_'"
     ]
    }
   ],
   "source": [
    "getCoverage(CLFstar1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=CLFstar1.estimators_[0]\n",
    "a=' '.join(list(A.tree_.feature.astype(str))).split('-2')\n",
    "b=[len(x.split()) for x in a if x != ' ']\n",
    "np.array(b).sum()*(10/2**9)\n",
    "#len(list(set(A.tree_.feature[A.tree_.feature>0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvLen(clf):\n",
    "    s=0\n",
    "    for e in clf.estimators_:\n",
    "        a=' '.join(list(e.tree_.feature.astype(str))).split('-2')\n",
    "        b=[len(x.split()) for x in a if x != ' ']\n",
    "        s=s+np.array(b).sum()*(10/2**9)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.2421875"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAvLen(CLFstar1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.73828125"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAvLen(CLFstar5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.2265625"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAvLen(CLFstar2)+getAvLen(CLFstar5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawTrees(model):\n",
    "    '''\n",
    "        draw the estimators (trees)\n",
    "        in a single model\n",
    "    '''\n",
    "    N=len(model.estimators_)\n",
    "\n",
    "    for count in range(N):\n",
    "        estimator = model.estimators_[count]\n",
    "\n",
    "        export_graphviz(estimator, out_file='tmptree.dot', \n",
    "                        #feature_names = iris.feature_names,\n",
    "                        #class_names = iris.target_names,\n",
    "                        rounded = True, proportion = False, \n",
    "                        precision = 2, filled = True)\n",
    "\n",
    "        from subprocess import call\n",
    "        call(['dot', '-Tpng', 'tmptree.dot', '-o', 'tmptree'+str(count)+'.png', '-Gdpi=600'])\n",
    "        from IPython.display import Image\n",
    "        Image(filename = 'tmptree'+str(count)+'.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawTrees(CLFstar5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "from scipy.interpolate import interp1d\n",
    "auc_=[]\n",
    "ROC={}\n",
    "fpr_ = np.linspace(0, 1, num=20, endpoint=True)\n",
    "for run in np.arange(1000):\n",
    "    clf=CLFstar\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "    y_pred=clf.predict_proba(X_test)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test,y_pred[:,1], pos_label=1)\n",
    "    f = interp1d(fpr, tpr)\n",
    "    auc_=np.append(auc_,metrics.auc(fpr_, f(fpr_)))\n",
    "    ROC[metrics.auc(fpr, tpr)]={'fpr':fpr_,'tpr':f(fpr_)}\n",
    "sns.distplot(auc_)\n",
    "auc_.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
